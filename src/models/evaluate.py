"""Utils for evaluating anomaly detection results."""

import pandas as pd


def validate_by_alertsdf(inlier_ids, outlier_ids, alerts_df):
    """Evaluate anomaly detection results based on alerts info."""
    # out of x in/out liers, y had alerts firing
    print(
        "{:.5f} % of total inliers had alerts firing".format(
            len(inlier_ids.intersection(alerts_df.index)) / len(inlier_ids)
        )
    )
    print(
        "{:.5f} % of total outliers had alerts firing".format(
            len(outlier_ids.intersection(alerts_df.index)) / len(outlier_ids)
        )
    )
    print()

    # how many total alerts in deployments
    num_inlier_alerts = alerts_df.reindex(inlier_ids).sum(axis=1)
    num_outlier_alerts = alerts_df.reindex(outlier_ids).sum(axis=1)

    # average number of alerts in in/out liers
    print("Mean num alerts in  inliers = {:.5f}".format(num_inlier_alerts.mean()))
    print("Mean num alerts in outliers = {:.5f}".format(num_outlier_alerts.mean()))
    print("Diff = {:.5f}".format(num_outlier_alerts.mean() - num_inlier_alerts.mean()))
    print()

    # median number of alerts in in/out liers
    print("Median num alerts in  inliers = {:.5f}".format(num_inlier_alerts.median()))
    print("Median num alerts in outliers = {:.5f}".format(num_outlier_alerts.median()))
    print(
        "Diff = {:.5f}".format(num_outlier_alerts.median() - num_inlier_alerts.median())
    )
    print()

    # get columns in alerts df that belong to each alert severity
    alertcols_by_sev = dict()
    for col in alerts_df.columns:
        # find severity of alert (alert type)
        # FIXME: assumes alert severity will be among these six
        head, tail = col.lower().split("_")
        if head == "none" or tail == "none":
            curr_severity = "none"
        elif head == "info" or tail == "info":
            curr_severity = "info"
        elif head == "alert" or tail == "alert":
            curr_severity = "alert"
        elif head == "warning" or tail == "warning":
            curr_severity = "warning"
        elif head == "high" or tail == "high":
            curr_severity = "high"
        elif head == "critical" or tail == "critical":
            curr_severity = "critical"
        else:
            print(f"Alert severity could not be identified for column {col}")

        # update dictionary
        if curr_severity not in alertcols_by_sev:
            alertcols_by_sev[curr_severity] = [col]
        else:
            alertcols_by_sev[curr_severity].append(col)

    # init stats df as columns generated by pd.DataFrame.describe()
    stats_df = pd.DataFrame(
        index=pd.MultiIndex.from_product(
            [alertcols_by_sev.keys(), ["inlier", "outlier"]],
            names=["severity", "label"],
        ),
        columns=["count", "mean", "std", "min", "25%", "50%", "75%", "max"],
    )

    # fill stats df
    for asev, asevcols in alertcols_by_sev.items():
        # get total number of alerts of severity `asev` in each in/out lier
        num_inlier_alerts = alerts_df.reindex(inlier_ids)[asevcols].sum(axis=1)
        num_outlier_alerts = alerts_df.reindex(outlier_ids)[asevcols].sum(axis=1)

        # get stats for inliers and outliers
        stats_df.loc[asev, "inlier"] = num_inlier_alerts.describe()
        stats_df.loc[asev, "outlier"] = num_outlier_alerts.describe()

    # rename for better understanding
    stats_df = stats_df.rename(columns={"count": "num_depls"})
    print(stats_df)


def validate_by_failingdf(inlier_ids, outlier_ids, failing_df):
    """
    Evaluate anomaly detection results based on failing info.

    In Red Hat, this info is in the cluster_version{type="failing"} metric
    """
    # out of the outliers, how many were present on the "failing clusters" list on grafana dashboard
    num_outliers_in_failing = outlier_ids.intersection(failing_df.index)
    num_inliers_in_failing = inlier_ids.intersection(failing_df.index)

    # len(num_outliers_in_failing) / len(outlier_ids), len(num_inliers_in_failing) / len(inlier_ids)
    print(
        f"Out of {len(outlier_ids)} deployments marked outliers, \
        {len(num_outliers_in_failing)} were in failing clusters list.\
        \nPercent = {len(num_outliers_in_failing) / len(outlier_ids)}"
    )
    print(
        f"Out of {len(inlier_ids)} deployments marked  inliers, \
        {len(num_inliers_in_failing)} were in failing clusters list.\
        \nPercent = {len(num_inliers_in_failing) / len(inlier_ids)}"
    )
    print()

    # out of the deployments marked failing (for the current cluster df),
    # how many were marked as outliers and how many inliers
    num_failing_in_outliers = failing_df.index.intersection(
        outlier_ids.append(inlier_ids)
    ).isin(outlier_ids)
    num_failing_in_inliers = failing_df.index.intersection(
        outlier_ids.append(inlier_ids)
    ).isin(inlier_ids)

    print(
        "Percent of deployments in failingdf that were found in  inliers = {:.5f}".format(
            num_failing_in_inliers.mean()
        )
    )
    print(
        "Percent of deployments in failingdf that were found in outliers = {:.5f}".format(
            num_failing_in_outliers.mean()
        )
    )
